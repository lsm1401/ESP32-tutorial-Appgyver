{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download and Load model from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-18 21:25:08.182253: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-18 21:25:15.320618: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Download model \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import boto3\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'hcp-24021b1a-cd5d-415f-a415-b76fdbc2f686'\n",
    "object_name = 'data/archive/fruits-360_dataset/fruits-360/model/e4efbee18a28f368/fruitmodel/model.h5'\n",
    "file_name = 'downloaded_model.h5'\n",
    "    \n",
    "s3.download_file(bucket_name, object_name, file_name)\n",
    "loaded_model = load_model(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 96, 96, 16)        80        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 96, 96, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 32)        2080      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 24, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 64)        8256      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 128)       32896     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4608)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 9218      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,530\n",
      "Trainable params: 52,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model \n",
    "#Integer only\n",
    "#Creating integer only models is a common use case for TensorFlow Lite for Microcontrollers.\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('/Users/i551982/Desktop/Github/ESP32-tutorial/downloaded_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Convert to Tensorflow model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/3v/kt3p4yx106n_9h7p5_4lqk7c0000gn/T/tmp6it86o0a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/3v/kt3p4yx106n_9h7p5_4lqk7c0000gn/T/tmp6it86o0a/assets\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "/Users/i551982/opt/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2022-09-18 21:25:46.291797: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-09-18 21:25:46.291815: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-09-18 21:25:46.292534: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/3v/kt3p4yx106n_9h7p5_4lqk7c0000gn/T/tmp6it86o0a\n",
      "2022-09-18 21:25:46.295707: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-09-18 21:25:46.295732: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/3v/kt3p4yx106n_9h7p5_4lqk7c0000gn/T/tmp6it86o0a\n",
      "2022-09-18 21:25:46.303130: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-09-18 21:25:46.304681: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-09-18 21:25:46.352057: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/3v/kt3p4yx106n_9h7p5_4lqk7c0000gn/T/tmp6it86o0a\n",
      "2022-09-18 21:25:46.365402: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 72870 microseconds.\n",
      "2022-09-18 21:25:46.394753: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64456"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WIDTH = 96\n",
    "HEIGHT = 96\n",
    "\n",
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "      data = np.random.rand(1, WIDTH, HEIGHT, 1)\n",
    "      yield [data.astype(np.float32)]\n",
    "      \n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE] #[tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "# converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "file = open( '/Users/i551982/Desktop/Github/ESP32-tutorial/converted_model.tflite' , 'wb' ) \n",
    "file.write( tflite_quant_model ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.float32'>\n",
      "output:  <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "#Check input and output format of quantized model \n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 : [[0.10546875 0.89453125]]\n",
      "Lemon\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#https://www.tensorflow.org/lite/performance/post_training_integer_quant\n",
    "#ESP-EYE Image \n",
    "#Apple \n",
    "\n",
    "import glob\n",
    "\n",
    "# image_path = '/Users/i551982/Desktop/Github/ESP32-tutorial/dataset/apple_0.jpg'\n",
    "# image_path = '/Users/i551982/Desktop/Github/ESP32-tutorial/dataset/apple_1.jpg'\n",
    "# image_path = '/Users/i551982/Desktop/Github/ESP32-tutorial/dataset/apple_2.jpg'\n",
    "# image_path = '/Users/i551982/Desktop/Github/ESP32-tutorial/dataset/lemon_0.jpg'\n",
    "image_path = '/Users/i551982/Desktop/Github/ESP32-tutorial/dataset/lemon_1.jpg'\n",
    "\n",
    "\n",
    "img_width =  96\n",
    "img_height = 96\n",
    "\n",
    "# 1. Read image\n",
    "img = tf.io.read_file(image_path)\n",
    "\n",
    "# 2. Decode and convert \n",
    "img = tf.io.decode_jpeg(img, channels=1)\n",
    "# print(\"Before convert type\")\n",
    "# print(img)\n",
    "# 3. Convert to float32 in [0, 1] range\n",
    "img = tf.image.convert_image_dtype(img, tf.float32) \n",
    "# img = tf.image.convert_image_dtype(img, tf.int8) \n",
    "# print(\"After\")\n",
    "# print(img)\n",
    "\n",
    "\n",
    "# # 4. Resize to the desired size\n",
    "img = tf.image.resize(img, [img_height, img_width], method='nearest') \n",
    "# print(\"Resize\")\n",
    "# print(img)\n",
    "\n",
    "# interpreter = tf.lite.Interpreter(model_path=\"/Users/i551982/Desktop/esp-eye/kaist-tutorial-1/converted_model_v20_1.tflite\") #Sanraj's model from AI Core\n",
    "interpreter = tf.lite.Interpreter(model_path=\"/Users/i551982/Desktop/esp-eye/kaist-tutorial-1/converted_model.tflite\") #Sanraj's model from AI Core\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "# print('interpreter', interpreter)\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.expand_dims(img, 0)\n",
    "# print('expand: ',img)\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "\n",
    "#print(interpreter.get_tensor(input_details[0]['index']))\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "preds = interpreter.get_tensor(output_details[0]['index'])\n",
    "# print(\"Preds:\",preds.shape)\n",
    "# print(i,\":\", preds)\n",
    "\n",
    "# apple_preds = np.append(apple_preds, preds)\n",
    "# lemon_preds = np.append(lemon_preds, preds)\n",
    "\n",
    "# print(preds.shape)\n",
    "# print(type(preds))\n",
    "pred_texts = np.argmax(preds)\n",
    "\n",
    "if pred_texts == 0: \n",
    "    pred_texts = \"Apple\"\n",
    "\n",
    "else: \n",
    "    pred_texts = \"Lemon\"\n",
    "    \n",
    "    \n",
    "print(pred_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Convert to C++ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can then run this command to convert the model to c code.\n",
    "```\n",
    "xxd -i converted_model.tflite > firmware/src/model_data.cc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfbcfb9dc2fb3a15156eff75324b2a106e1f6a8466111164ee2b5b7456209a7b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
